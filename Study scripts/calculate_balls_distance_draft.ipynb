{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Parametros\n",
    "filename = \"foto3.jpg\"\n",
    "\n",
    "real_height = 400   # mm\n",
    "image_height = 1080 # pixels\n",
    "sensor_height = 5.4 # mm  \n",
    "focal_length = 18   # mm\n",
    "\n",
    "def calculate_distance(radius):\n",
    "    # https://photo.stackexchange.com/questions/12434/how-do-i-calculate-the-distance-of-an-object-in-a-photo\n",
    "    dem = focal_length * real_height * image_height \n",
    "    num = sensor_height * 2*radius \n",
    "    \n",
    "    distance_meters = dem/num/1000 \n",
    "\n",
    "    return distance_meters # meters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz o pre processamento da imagem para colocar nas funções de detecção de circulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image. \n",
    "img = cv2.imread(filename, cv2.IMREAD_COLOR) \n",
    "\n",
    "def blur_image(img, kernel=3,ERO=False,DIL=False,kernel2=3):\n",
    "    # blur image, and maybe Erode and Dilate\n",
    "\n",
    "    # Convert to grayscale. \n",
    "    if len(img.shape) > 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # Blur using kernel. \n",
    "    gray_blurred = cv2.blur(img, (kernel, kernel)) \n",
    "\n",
    "    # gray_blurred = cv2.medianBlur(gray, 3) \n",
    "    \n",
    "    \n",
    "    if ERO:\n",
    "        ero = cv2.erode(gray_blurred, np.ones((kernel2 ,kernel2)))\n",
    "        gray_blurred = ero\n",
    "    if DIL:\n",
    "        dil = cv2.dilate(gray_blurred, np.ones((kernel2,kernel2)))\n",
    "        gray_blurred = dil\n",
    "\n",
    "    return gray_blurred\n",
    "\n",
    "processed_img = blur_image(img,kernel=3)\n",
    "\n",
    "cv2.imshow('teste',processed_img)\n",
    "plt.show()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENTANDO VIA FILTRO DE COR\n",
    "# Chutei uma cor para filtrar em uma imagem especifica. Foi o que deu mais resultado até agora.\n",
    "\n",
    "img = cv2.imread(filename, cv2.IMREAD_COLOR) \n",
    "\n",
    "\n",
    "lower_blue = np.array([0, 0, 0]) \n",
    "upper_blue = np.array([255, 255, 150]) \n",
    "\n",
    "img = cv2.blur(img, (3, 3)) \n",
    "processed_img = img\n",
    "\n",
    "ero = cv2.erode(img, np.ones((5, 5)))\n",
    "processed_img = ero\n",
    "\n",
    "dil = cv2.dilate(processed_img, np.ones((3,3)))\n",
    "processed_img = dil\n",
    "\n",
    "\n",
    "# preparing the mask to overlay \n",
    "mask = cv2.inRange(processed_img, lower_blue, upper_blue) \n",
    "\n",
    "result = cv2.bitwise_and(processed_img,processed_img,mask = mask) \n",
    "processed_img = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "\n",
    "# cv2.imshow(\"filtro\",ero)\n",
    "# plt.show()\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# # cv2.imshow(\"filtro\",gray_blurred)\n",
    "# # plt.show()\n",
    "# # cv2.waitKey()\n",
    "# # cv2.destroyAllWindows()\n",
    "\n",
    "# cv2.imshow(\"filtro\",img)\n",
    "# plt.show()\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow(\"filtro\",result)\n",
    "plt.show()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Hough transform \n",
    "detected_circles = cv2.HoughCircles(processed_img,  \n",
    "                   cv2.HOUGH_GRADIENT, 2, 50, param1 = 50, # param1 = 50, param2= 10\n",
    "                    param2 = 10, minRadius = 2, maxRadius =8) \n",
    "\n",
    "# print(len(detected_circles))\n",
    "# Draw circles that are detected. \n",
    "if detected_circles is not None: \n",
    "  \n",
    "    # Convert the circle parameters a, b and r to integers. \n",
    "    # print(detected_circles)\n",
    "    # detected_circles = np.uint16(np.around(detected_circles)) \n",
    "  \n",
    "    for pt in detected_circles[0, :]: \n",
    "        a, b, r = pt[0], pt[1], pt[2] \n",
    "        a, b, r = np.uint16((a,b,r))\n",
    "\n",
    "        # Draw the circumference of the circle. \n",
    "        cv2.circle(img, (a, b), r, (0, 255, 0), 1) \n",
    "        cv2.circle(processed_img, (a, b), r, (0, 255, 0), 1) \n",
    "\n",
    "        text = str( round(calculate_distance(pt[2])) )\n",
    "\n",
    "        # cv2.putText(processed_img,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "        cv2.putText(img,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "\n",
    "cv2.imshow(\"Detected Circle\", processed_img) \n",
    "plt.show()\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "cv2.imshow(\"Detected Circle\", img) \n",
    "plt.show()\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar a figura\n",
    "cv2.imwrite(\"circles_output_\"+ filename, img) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentar selcionar por click\n",
    "Deu muito certo essa tentativa não\n",
    "\n",
    "A ideia era clicar nas bolas, para pegar as cores dela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677   445\n",
      "750   732\n",
      "1142   159\n",
      "1108   568\n",
      "[[677, 445], [750, 732], [1142, 159], [1108, 568]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(filename, cv2.IMREAD_COLOR) \n",
    "\n",
    "def click_event(event, x, y, flags, params): \n",
    "    global pos_click\n",
    "    # checking for left mouse clicks \n",
    "    if event == cv2.EVENT_LBUTTONDOWN: \n",
    "  \n",
    "        # displaying the coordinates \n",
    "        # on the Shell \n",
    "        pos_click.append([x,y])\n",
    "        print(x, ' ', y) \n",
    "  \n",
    "        # displaying the coordinates \n",
    "        # on the image window \n",
    "        # font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "        # cv2.putText(img, str(x) + ',' +\n",
    "        #             str(y), (x,y), font, \n",
    "        #             1, (255, 0, 0), 2) \n",
    "        cv2.imshow('image', img) \n",
    "\n",
    "    return x\n",
    "\n",
    "pos_click = []\n",
    "cv2.imshow('image',img)\n",
    "plt.show()\n",
    "cv2.setMouseCallback('image', click_event) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(pos_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COLOR_BGR 2 RGB\n",
    "def change_rgb(input):\n",
    "    # return [input[1], input[2],input[0]]\n",
    "    return [input[2], input[1],input[0]]\n",
    "\n",
    "change_rgb([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limiar = 20\n",
    "\n",
    "colors = []\n",
    "for i in range(len(pos_click)):\n",
    "    # print(pos_click[i])\n",
    "    colors.append(change_rgb(img[pos_click[i][1]][pos_click[i][0]] ))\n",
    "    # print( img[pos_click[i][1]][pos_click[i][0]] )\n",
    "\n",
    "colors_min_max = [colors + limiar*np.ones(np.shape(colors),dtype=int) , colors, colors - limiar*np.ones(np.shape(colors),dtype=int)]\n",
    "print(np.shape(colors_min_max))\n",
    "plt.imshow(colors_min_max)\n",
    "plt.show()\n",
    "# print(np.shape(colors) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "folga = 10\n",
    "\n",
    "\n",
    "def unions(a):\n",
    "    # a = [(7, 10), (11, 13), (11, 15), (14, 20), (23, 39)]\n",
    "    b = []\n",
    "    for begin,end in sorted(a):\n",
    "        if b and b[-1][1] >= begin - 1:\n",
    "            b[-1][1] = max(b[-1][1], end)\n",
    "        else:\n",
    "            b.append([begin, end])\n",
    "    return b\n",
    "\n",
    "# unions(B_intervals)\n",
    "\n",
    "# mask = cv2.inRange(processed_img, lower_thr, upper_thr) \n",
    "\n",
    "def create_composite_mask(img,colors, folga=10):\n",
    "    \n",
    "    R_intervals = [(c[0]-folga,c[0]+folga) for c in colors]\n",
    "    G_intervals = [(c[1]-folga,c[1]+folga) for c in colors]\n",
    "    B_intervals = [(c[2]-folga,c[2]+folga) for c in colors]\n",
    "\n",
    "    mask_R = np.zeros(img.shape[:2])\n",
    "    mask_G = np.zeros(img.shape[:2])\n",
    "    mask_B = np.zeros(img.shape[:2])\n",
    "    for R in R_intervals:\n",
    "        # print(R[0], R[1])\n",
    "        mask_R = (mask_R + cv2.inRange(img, \n",
    "                                     np.array([R[0],0,0]), \n",
    "                                     np.array([R[1],255,255]) \n",
    "                                     )  # bitwise or\n",
    "                )\n",
    "    mask_R = mask_R.clip(0,255)\n",
    "    for G in G_intervals:\n",
    "        mask_G = (mask_G + cv2.inRange(img, \n",
    "                                     np.array([0,G[0],0]), \n",
    "                                     np.array([255,G[1],255]) \n",
    "                                     )  # bitwise or\n",
    "                )\n",
    "    mask_G = mask_G.clip(0,255)\n",
    "\n",
    "    for B in B_intervals:\n",
    "        mask_B = (mask_B + cv2.inRange(img, \n",
    "                                     np.array([0,0,B[0]]), \n",
    "                                     np.array([255,255,B[1]]) \n",
    "                                     )  # bitwise or\n",
    "                )\n",
    "    mask_B = mask_B.clip(0,255)\n",
    "    \n",
    "    # return mask_R,mask_G,mask_B\n",
    "    return (np.multiply(mask_R,np.multiply(mask_B,mask_G) )/255/255).astype(np.uint8)\n",
    "\n",
    "mask = create_composite_mask(img,colors, folga=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.uint8' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[289], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     upper_thr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(R), \u001b[38;5;28mmax\u001b[39m(G), \u001b[38;5;28mmax\u001b[39m(B)] \u001b[38;5;241m+\u001b[39m folga\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lower_thr, upper_thr\n\u001b[1;32m---> 13\u001b[0m calculate_color_threshold(colors,\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[289], line 10\u001b[0m, in \u001b[0;36mcalculate_color_threshold\u001b[1;34m(colors, folga)\u001b[0m\n\u001b[0;32m      7\u001b[0m B \u001b[38;5;241m=\u001b[39m [colors[i][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(np\u001b[38;5;241m.\u001b[39mshape(colors)[\u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m      9\u001b[0m lower_thr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmin\u001b[39m(R), \u001b[38;5;28mmin\u001b[39m(G), \u001b[38;5;28mmin\u001b[39m(B)] \u001b[38;5;241m-\u001b[39m folga\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m---> 10\u001b[0m upper_thr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(R), \u001b[38;5;28mmax\u001b[39m(G), \u001b[38;5;28mmax\u001b[39m(B)] \u001b[38;5;241m+\u001b[39m folga\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lower_thr, upper_thr\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.uint8' object is not callable"
     ]
    }
   ],
   "source": [
    "np.shape(colors)[0]\n",
    "\n",
    "# R, G, B\n",
    "def calculate_color_threshold(colors,folga):\n",
    "    R = [colors[i][0] for i in range(np.shape(colors)[0])]\n",
    "    G = [colors[i][1] for i in range(np.shape(colors)[0])]\n",
    "    B = [colors[i][2] for i in range(np.shape(colors)[0])]\n",
    "\n",
    "    lower_thr = [min(R), min(G), min(B)] - folga*np.ones((1,3))\n",
    "    upper_thr = [max(R), max(G), max(B)] + folga*np.ones((1,3))\n",
    "    return lower_thr, upper_thr\n",
    "\n",
    "calculate_color_threshold(colors,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.uint8' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[291], line 34\u001b[0m\n\u001b[0;32m     29\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processed_img\n\u001b[1;32m---> 34\u001b[0m preprocess_img(filename,colors,folga \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m, show_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[291], line 5\u001b[0m, in \u001b[0;36mpreprocess_img\u001b[1;34m(filename, colors, folga, show_graph)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_img\u001b[39m(filename,colors,folga \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, show_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# TENTANDO VIA FILTRO DE COR\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(filename, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR) \n\u001b[1;32m----> 5\u001b[0m     lower_thr, upper_thr \u001b[38;5;241m=\u001b[39m calculate_color_threshold(colors,folga)\n\u001b[0;32m      8\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mblur(img, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)) \n\u001b[0;32m      9\u001b[0m     processed_img \u001b[38;5;241m=\u001b[39m img\n",
      "Cell \u001b[1;32mIn[289], line 10\u001b[0m, in \u001b[0;36mcalculate_color_threshold\u001b[1;34m(colors, folga)\u001b[0m\n\u001b[0;32m      7\u001b[0m B \u001b[38;5;241m=\u001b[39m [colors[i][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(np\u001b[38;5;241m.\u001b[39mshape(colors)[\u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m      9\u001b[0m lower_thr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmin\u001b[39m(R), \u001b[38;5;28mmin\u001b[39m(G), \u001b[38;5;28mmin\u001b[39m(B)] \u001b[38;5;241m-\u001b[39m folga\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m---> 10\u001b[0m upper_thr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(R), \u001b[38;5;28mmax\u001b[39m(G), \u001b[38;5;28mmax\u001b[39m(B)] \u001b[38;5;241m+\u001b[39m folga\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lower_thr, upper_thr\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.uint8' object is not callable"
     ]
    }
   ],
   "source": [
    "def preprocess_img(filename,colors,folga = 10, show_graph = False):\n",
    "    # TENTANDO VIA FILTRO DE COR\n",
    "    img = cv2.imread(filename, cv2.IMREAD_COLOR) \n",
    "\n",
    "    lower_thr, upper_thr = calculate_color_threshold(colors,folga)\n",
    "\n",
    "\n",
    "    img = cv2.blur(img, (3, 3)) \n",
    "    processed_img = img\n",
    "\n",
    "    ero = cv2.erode(img, np.ones((5, 5)))\n",
    "    processed_img = ero\n",
    "\n",
    "    dil = cv2.dilate(processed_img, np.ones((3,3)))\n",
    "    processed_img = dil\n",
    "\n",
    "\n",
    "    # preparing the mask to overlay \n",
    "    # mask = cv2.inRange(processed_img, lower_thr, upper_thr) \n",
    "    mask = create_composite_mask(processed_img, colors, folga)\n",
    "\n",
    "    result = cv2.bitwise_and(processed_img,processed_img,mask = mask) \n",
    "    processed_img = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    if show_graph:\n",
    "        cv2.imshow(\"Imagem Filtrada de cor\",result)\n",
    "        plt.show()\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return processed_img\n",
    "\n",
    "\n",
    "preprocess_img(filename,colors,folga = 30, show_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1141. ,  159. ,    6.8], dtype=float32),\n",
       " array([1085. ,  785. ,    3.4], dtype=float32),\n",
       " array([749., 733.,   4.], dtype=float32)]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Hough transform \n",
    "detected_circles = cv2.HoughCircles(processed_img,  \n",
    "                   cv2.HOUGH_GRADIENT, 2, 50, param1 = 50, # param1 = 50, param2= 10\n",
    "               param2 = 10, minRadius = 1, maxRadius =8) \n",
    "\n",
    "r_folga = 10\n",
    "new_detected_circles = [pt for pt in detected_circles[0, :] if any([(i[0]-pt[0])**2 + (i[1]-pt[1])**2 <= r + r_folga for i in pos_click])]\n",
    "\n",
    "new_detected_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Hough transform \n",
    "detected_circles = cv2.HoughCircles(processed_img,  \n",
    "                   cv2.HOUGH_GRADIENT, 2, 50, param1 = 50, # param1 = 50, param2= 10\n",
    "               param2 = 10, minRadius = 1, maxRadius =8) \n",
    "\n",
    "r_folga = 10\n",
    "\n",
    "# print(len(detected_circles))\n",
    "# Draw circles that are detected. \n",
    "if detected_circles is not None: \n",
    "  \n",
    "    # Convert the circle parameters a, b and r to integers. \n",
    "    # print(detected_circles)\n",
    "    # detected_circles = np.uint16(np.around(detected_circles)) \n",
    "  \n",
    "    for pt in detected_circles[0, :]: \n",
    "        a, b, r = pt[0], pt[1], pt[2]\n",
    "        # (x-x0)^2 + (y-y0)^2 <= r \n",
    "        if True:\n",
    "            a, b, r = np.uint16((a,b,r))\n",
    "\n",
    "            # Draw the circumference of the circle. \n",
    "            cv2.circle(img, (a, b), r, (0, 255, 0), 1) \n",
    "            cv2.circle(processed_img, (a, b), r, (0, 255, 0), 1) \n",
    "\n",
    "            # Draw a small circle (of radius 1) to show the center. \n",
    "            # cv2.circle(img, (a, b), 1, (0, 0, 255), 3) \n",
    "            # cv2.imshow(\"Detected Circle\", img) \n",
    "            # time.sleep(1)\n",
    "            text = str( round(calculate_distance(pt[2])) )\n",
    "            # text = str( round(pt[2],1) )\n",
    "\n",
    "            # print(text)\n",
    "            # cv2.putText(gray_blurred,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "            cv2.putText(img,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "\n",
    "cv2.imshow(\"Detected Circle\", processed_img) \n",
    "plt.show()\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "cv2.imshow(\"Detected Circle\", img) \n",
    "plt.show()\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image. \n",
    "img = cv2.imread(filename, cv2.IMREAD_COLOR) \n",
    "# print(img)\n",
    "# img = result\n",
    "\n",
    "\n",
    "\n",
    "# Convert to grayscale. \n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "# gray = cv2.cvtColor(img, 83) \n",
    "\n",
    "\n",
    "# Blur using 3 * 3 kernel. \n",
    "processed_img = cv2.blur(gray, (3, 3)) \n",
    "\n",
    "\n",
    "\n",
    "# # # Adaptive thresholding to handle varying lighting and shadows\n",
    "# adaptive_thresh = cv2.adaptiveThreshold(\n",
    "#     gray_blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 1\n",
    "# )\n",
    "# gray_blurred = adaptive_thresh\n",
    "\n",
    "# Use morphological closing to fill gaps caused by shadows\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "closed = cv2.morphologyEx(processed_img, cv2.MORPH_CLOSE, kernel)\n",
    "processed_img = closed\n",
    "\n",
    "canny = cv2.Canny(processed_img,50,10)\n",
    "\n",
    "cv2.imshow('teste',processed_img)\n",
    "plt.show()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(processed_img,50,10)\n",
    "\n",
    "cv2.imshow('teste',canny)\n",
    "plt.show()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo por matematica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "altura_torre = 115360 + 9640 \n",
    "altura_camera = 12000 + 4360 + 12000 + 2500\n",
    "metade_horizontal = 14300\n",
    "offset_horizontal = 0 \n",
    "camera_horizontal = metade_horizontal - offset_horizontal\n",
    "\n",
    "tamanho_vao = 824 ## verificar\n",
    "tamanho_cabo = 1200 ## verificar\n",
    "\n",
    "ratio = tamanho_cabo/tamanho_vao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24688"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altura_camera/altura_torre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.functions.elementary.hyperbolic import cosh, sinh\n",
    "\n",
    "def catenary(x, a,b,c):\n",
    "    return c + a*cosh((x-b)/a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.54308063481524$"
      ],
      "text/plain": [
       "1.54308063481524"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catenary(1,1,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "matrix is numerically singular",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m y2 \u001b[38;5;241m=\u001b[39m y1\n\u001b[0;32m     13\u001b[0m ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m---> 15\u001b[0m nsolve((catenary(x1,argA,argB,argC)\u001b[38;5;241m-\u001b[39my1,\n\u001b[0;32m     16\u001b[0m         catenary(x2,argA,argB,argC)\u001b[38;5;241m-\u001b[39my2,     \n\u001b[0;32m     17\u001b[0m         ratio\u001b[38;5;241m*\u001b[39msqrt(x2\u001b[38;5;241m^\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (y2\u001b[38;5;241m-\u001b[39my1)\u001b[38;5;241m^\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m argA \u001b[38;5;241m*\u001b[39m(sinh((x2\u001b[38;5;241m-\u001b[39margB)\u001b[38;5;241m/\u001b[39margA) \u001b[38;5;241m+\u001b[39m sinh(argB\u001b[38;5;241m/\u001b[39margA))\n\u001b[0;32m     18\u001b[0m         ), \n\u001b[0;32m     19\u001b[0m        (argA, argB, argC), \n\u001b[0;32m     20\u001b[0m        (random\u001b[38;5;241m.\u001b[39mrandom()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,x2\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m,y1))\n",
      "File \u001b[1;32mc:\\Users\\plima\\anaconda3\\Lib\\site-packages\\sympy\\utilities\\decorator.py:87\u001b[0m, in \u001b[0;36mconserve_mpmath_dps.<locals>.func_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m dps \u001b[38;5;241m=\u001b[39m mpmath\u001b[38;5;241m.\u001b[39mmp\u001b[38;5;241m.\u001b[39mdps\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     mpmath\u001b[38;5;241m.\u001b[39mmp\u001b[38;5;241m.\u001b[39mdps \u001b[38;5;241m=\u001b[39m dps\n",
      "File \u001b[1;32mc:\\Users\\plima\\anaconda3\\Lib\\site-packages\\sympy\\solvers\\solvers.py:3104\u001b[0m, in \u001b[0;36mnsolve\u001b[1;34m(dict, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3102\u001b[0m J \u001b[38;5;241m=\u001b[39m lambdify(fargs, J, modules)\n\u001b[0;32m   3103\u001b[0m \u001b[38;5;66;03m# solve the system numerically\u001b[39;00m\n\u001b[1;32m-> 3104\u001b[0m x \u001b[38;5;241m=\u001b[39m findroot(f, x0, J\u001b[38;5;241m=\u001b[39mJ, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_dict:\n\u001b[0;32m   3106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(fargs, [sympify(xi) \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m x]))]\n",
      "File \u001b[1;32mc:\\Users\\plima\\anaconda3\\Lib\\site-packages\\mpmath\\calculus\\optimization.py:969\u001b[0m, in \u001b[0;36mfindroot\u001b[1;34m(ctx, f, x0, solver, tol, verbose, verify, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     maxsteps \u001b[38;5;241m=\u001b[39m iterations\u001b[38;5;241m.\u001b[39mmaxsteps\n\u001b[0;32m    968\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 969\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, error \u001b[38;5;129;01min\u001b[39;00m iterations:\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    971\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx:    \u001b[39m\u001b[38;5;124m'\u001b[39m, x)\n",
      "File \u001b[1;32mc:\\Users\\plima\\anaconda3\\Lib\\site-packages\\mpmath\\calculus\\optimization.py:660\u001b[0m, in \u001b[0;36mMDNewton.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    658\u001b[0m fxn \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mfx\n\u001b[0;32m    659\u001b[0m Jx \u001b[38;5;241m=\u001b[39m J(\u001b[38;5;241m*\u001b[39mx0)\n\u001b[1;32m--> 660\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39mlu_solve(Jx, fxn)\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJx:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\plima\\anaconda3\\Lib\\site-packages\\mpmath\\matrices\\linalg.py:224\u001b[0m, in \u001b[0;36mLinearAlgebraMethods.lu_solve\u001b[1;34m(ctx, A, b, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m         x \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mlu_solve(A, b)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# LU factorization\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     A, p \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mLU_decomp(A)\n\u001b[0;32m    225\u001b[0m     b \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mL_solve(A, b, p)\n\u001b[0;32m    226\u001b[0m     x \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mU_solve(A, b)\n",
      "File \u001b[1;32mc:\\Users\\plima\\anaconda3\\Lib\\site-packages\\mpmath\\matrices\\linalg.py:149\u001b[0m, in \u001b[0;36mLinearAlgebraMethods.LU_decomp\u001b[1;34m(ctx, A, overwrite, use_cache)\u001b[0m\n\u001b[0;32m    147\u001b[0m             A[i,k] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m A[i,j]\u001b[38;5;241m*\u001b[39mA[j,k]\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mabsmin(A[n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tol:\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatrix is numerically singular\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# cache decomposition\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orig, ctx\u001b[38;5;241m.\u001b[39mmatrix):\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: matrix is numerically singular"
     ]
    }
   ],
   "source": [
    "from sympy import Symbol, nsolve, sqrt\n",
    "import random\n",
    "\n",
    "argA = Symbol('a')\n",
    "argB = Symbol('b')\n",
    "argC = Symbol('c')\n",
    "\n",
    "x1 = 0\n",
    "y1 = 1000\n",
    "x2 = tamanho_vao\n",
    "y2 = y1\n",
    "\n",
    "ratio = 1.5\n",
    "\n",
    "nsolve((catenary(x1,argA,argB,argC)-y1,\n",
    "        catenary(x2,argA,argB,argC)-y2,     \n",
    "        ratio*sqrt(x2^2 + (y2-y1)^2) - argA *(sinh((x2-argB)/argA) + sinh(argB/argA))\n",
    "        ), \n",
    "       (argA, argB, argC), \n",
    "       (random.random()*10+1,x2/2,y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Anything V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch \n",
    "import numpy as np\n",
    "# from Depth-Anything-V2.depth_anything_v2.dpt import DepthAnythingV2\n",
    "import importlib\n",
    "dpt = importlib.import_module(\"Depth-Anything-V2.depth_anything_v2.dpt\")\n",
    "DepthAnythingV2 = dpt.DepthAnythingV2\n",
    "\n",
    "util_transform = importlib.import_module(\"Depth-Anything-V2.depth_anything_v2.util.transform\")\n",
    "\n",
    "filename='foto3.jpg'\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def filter_detection(roi, r, circ_thresh=0.6, fill_thresh=0.6):\n",
    "    \"\"\"\n",
    "    Check if the ROI (grayscale) is near-circular and filled.\n",
    "    Uses Otsu's thresholding and contour analysis.\n",
    "    Returns True if both circularity and fill ratio exceed the thresholds.\n",
    "    \"\"\"\n",
    "    ret, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return False\n",
    "    cnt = max(contours, key=cv2.contourArea)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    if perimeter == 0:\n",
    "        return False\n",
    "    circularity = 4 * math.pi * (area / (perimeter * perimeter))\n",
    "    expected_area = math.pi * (r ** 2)\n",
    "    fill_ratio = area / expected_area if expected_area > 0 else 0\n",
    "    return (circularity >= circ_thresh) and (fill_ratio >= fill_thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop the image, so its size is multiple of 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated 0.0 Gb\n",
      "DEVICE: cuda\n",
      "0.0 6.939051\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/DepthAnything/Depth-Anything-V2?tab=readme-ov-file\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Memory allocated\", torch.cuda.memory_allocated()/1024/1024/1024,\"Gb\")\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n",
    "    \n",
    "encoder = 'vitb' # or 'vits', 'vitl', 'vitg'\n",
    "\n",
    "depth_anything = DepthAnythingV2(**model_configs[encoder])\n",
    "depth_anything.load_state_dict(torch.load(f'Depth-Anything-V2/depth_anything_v2_{encoder}.pth', map_location='cpu'))\n",
    "depth_anything = depth_anything.to(DEVICE).eval()\n",
    "\n",
    "raw_image = cv2.imread(filename)\n",
    "\n",
    "# Crop the image, so its size is multiple of 14\n",
    "a,b,_ = raw_image.shape\n",
    "np.floor(a/14)*14\n",
    "np.floor(b/14)*14\n",
    "raw_image = raw_image[:int(np.floor(a/14)*14),:int(np.floor(b/14)*14),:]\n",
    "\n",
    "\n",
    "depth = depth_anything.infer_image(raw_image,   np.floor(a/14)*14)\n",
    "\n",
    "depth = (depth - depth.min()) / (depth.max() - depth.min()) * 255.0\n",
    "depth = depth.astype(np.uint8)\n",
    "\n",
    "depth\n",
    "print(depth.min(), depth.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = (depth - depth.min()) / (depth.max() - depth.min()) * 255.0\n",
    "depth = depth.astype(np.uint8)\n",
    "\n",
    "cv2.imshow('depth',depth)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_img = depth.copy()\n",
    "\n",
    "canny = cv2.Canny(processed_img,50,50)\n",
    "\n",
    "cv2.imshow('teste',canny)\n",
    "plt.show()\n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_depth_in_a_circle(depth, pt):\n",
    "    x,y = pt[0],pt[1]\n",
    "    r = pt[2]\n",
    "\n",
    "    # print(x,y,r)\n",
    "    ix_min, ix_max = (np.max([np.floor(x-r),0]).astype(int), np.min([np.ceil(x+r),1918-1]).astype(int))\n",
    "    iy_min, iy_max = (np.max([np.floor(y-r),0]).astype(int), np.min([np.ceil(y+r),1078-1]).astype(int))\n",
    "\n",
    "    max = 0\n",
    "    for ix in range(ix_min, ix_max):\n",
    "        for iy in range(iy_min, iy_max):\n",
    "            if( (ix-x)**2 + (iy-y)**2 <= r**2):\n",
    "                # print(ix,iy,depth[iy,ix],depth[iy,ix]>max)\n",
    "                if depth[iy,ix] > max:\n",
    "                    max = depth[iy,ix]\n",
    "                # else:\n",
    "                #     if max == 0:\n",
    "                #         print('depth: ',depth[iy,ix])\n",
    "\n",
    "\n",
    "    # cv2.rectangle(raw_image, [ix_min,iy_max], [ix_min+10,iy_max-10], color = (0, 255, 0), thickness=1)\n",
    "    # cv2.rectangle(raw_image, [ix_min,iy_min], [ix_max,iy_max], color = (255, 0, 0), thickness=1)\n",
    "    # cv2.putText(raw_image,\"oi\",(x,y),fontFace=1,fontScale=1,color=255)\n",
    "\n",
    "    return max\n",
    "\n",
    "check_depth_in_a_circle(depth, [10,10,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENTANDO VIA FILTRO DE COR\n",
    "# Chutei uma cor para filtrar em uma imagem especifica. Foi o que deu mais resultado até agora.\n",
    "\n",
    "raw_image = cv2.imread(filename)\n",
    "a,b,_ = raw_image.shape\n",
    "np.floor(a/14)*14\n",
    "np.floor(b/14)*14\n",
    "raw_image = raw_image[:int(np.floor(a/14)*14),:int(np.floor(b/14)*14),:]\n",
    "\n",
    "\n",
    "# preparing the mask to overlay \n",
    "mask = cv2.inRange(raw_image, lower_blue, upper_blue) \n",
    "result = cv2.bitwise_and(raw_image,raw_image,mask = mask) \n",
    "processed_img = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "\n",
    "lower_blue = np.array([0, 0, 0]) \n",
    "upper_blue = np.array([255, 255, 150]) \n",
    "\n",
    "img = cv2.blur(raw_image, (3, 3)) \n",
    "processed_img = img\n",
    "\n",
    "ero = cv2.erode(img, np.ones((5, 5)))\n",
    "processed_img = ero\n",
    "\n",
    "dil = cv2.dilate(processed_img, np.ones((3,3)))\n",
    "processed_img = dil\n",
    "\n",
    "\n",
    "# # preparing the mask to overlay \n",
    "# mask = cv2.inRange(processed_img, lower_blue, upper_blue) \n",
    "# result = cv2.bitwise_and(processed_img,processed_img,mask = mask) \n",
    "# processed_img = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "\n",
    "# cv2.imshow(\"filtro\",ero)\n",
    "# plt.show()\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# # cv2.imshow(\"filtro\",gray_blurred)\n",
    "# # plt.show()\n",
    "# # cv2.waitKey()\n",
    "# # cv2.destroyAllWindows()\n",
    "\n",
    "# cv2.imshow(\"filtro\",img)\n",
    "# plt.show()\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow(\"filtro\",processed_img)\n",
    "plt.show()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\hough.cpp:2269: error: (-215:Assertion failed) !_image.empty() && _image.type() == CV_8UC1 && (_image.isMat() || _image.isUMat()) in function 'cv::HoughCircles'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # Apply Hough transform \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# raw_image = cv2.imread(filename)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# a,b,_ = raw_image.shape\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# processed_img = depth.copy()\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# processed_img = blur_image(processed_img,3,True,True)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m detected_circles \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mHoughCircles(processed_img,  \n\u001b[0;32m     13\u001b[0m                    cv2\u001b[38;5;241m.\u001b[39mHOUGH_GRADIENT, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m50\u001b[39m, \n\u001b[0;32m     14\u001b[0m                    param1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m,     param2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;66;03m# param1 = 50, param2= 10\u001b[39;00m\n\u001b[0;32m     15\u001b[0m                    minRadius \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,   maxRadius \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m) \n\u001b[0;32m     18\u001b[0m vector_compare_radius_depth \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# print(len(detected_circles))\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Draw circles that are detected. \u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\hough.cpp:2269: error: (-215:Assertion failed) !_image.empty() && _image.type() == CV_8UC1 && (_image.isMat() || _image.isUMat()) in function 'cv::HoughCircles'\n"
     ]
    }
   ],
   "source": [
    "# # Apply Hough transform \n",
    "# raw_image = cv2.imread(filename)\n",
    "# a,b,_ = raw_image.shape\n",
    "# np.floor(a/14)*14\n",
    "# np.floor(b/14)*14\n",
    "# raw_image = raw_image[:int(np.floor(a/14)*14),:int(np.floor(b/14)*14),:]\n",
    "\n",
    "# processed_img = depth.copy()\n",
    "# processed_img = blur_image(processed_img,3,True,True)\n",
    "\n",
    "\n",
    "detected_circles = cv2.HoughCircles(processed_img,  \n",
    "                   cv2.HOUGH_GRADIENT, 2, 50, \n",
    "                   param1 = 20,     param2 = 5, # param1 = 50, param2= 10\n",
    "                   minRadius = 1,   maxRadius =8) \n",
    "\n",
    "\n",
    "vector_compare_radius_depth = []\n",
    "\n",
    "# print(len(detected_circles))\n",
    "# Draw circles that are detected. \n",
    "if detected_circles is not None: \n",
    "\n",
    "    for pt in detected_circles[0, :]: \n",
    "        a, b, r = pt[0], pt[1], pt[2] \n",
    "        a, b, r = np.uint16((a,b,r))\n",
    "        depth_of_circle  = check_depth_in_a_circle(depth, pt)\n",
    "        if depth_of_circle < 70:\n",
    "            continue         \n",
    "\n",
    "        # Draw the circumference of the circle. \n",
    "\n",
    "        # Draw a small circle (of radius 1) to show the center. \n",
    "        # cv2.circle(img, (a, b), 1, (0, 0, 255), 3) \n",
    "        \n",
    "        # Write distances\n",
    "        text = str( round(calculate_distance(pt[2]) ) ) + '-' +str(round(depth_of_circle))\n",
    "        # text = str(round(depth_of_circle))\n",
    "        # text = str( round(pt[2],1) )\n",
    "        \n",
    "        \n",
    "        # Extract ROI for extra filtering\n",
    "        x_start = max(a - r, 0)\n",
    "        y_start = max(b - r, 0)\n",
    "        x_end = min(a + r, processed_img.shape[1])\n",
    "        y_end = min(b + r, processed_img.shape[0])\n",
    "        roi = processed_img[y_start:y_end, x_start:x_end]\n",
    "        \n",
    "        # Apply extra filtering with relaxed thresholds\n",
    "        if filter_detection(roi, r, circ_thresh=0.6, fill_thresh=0.6):\n",
    "            cv2.circle(raw_image, (a, b), r, (0, 255, 0), 1) \n",
    "            cv2.circle(processed_img, (a, b), r, (0, 255, 0), 1) \n",
    "\n",
    "            # print(text)\n",
    "            cv2.putText(processed_img,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "            cv2.putText(raw_image,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "            vector_compare_radius_depth.append([a, b, calculate_distance(pt[2]), depth_of_circle])\n",
    "\n",
    "cv2.imshow(\"Detected Circle\", processed_img) \n",
    "plt.show()\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "cv2.imshow(\"Detected Circle\", raw_image) \n",
    "plt.show()\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[613.0, 473.0, 170],\n",
       " [689.0, 737.0, 107],\n",
       " [719.0, 841.0, 104],\n",
       " [667.0, 673.0, 119],\n",
       " [747.0, 945.0, 82],\n",
       " [951.0, 983.0, 63],\n",
       " [939.0, 877.0, 60],\n",
       " [791.0, 1061.0, 68],\n",
       " [627.0, 525.0, 145],\n",
       " [645.0, 611.0, 136],\n",
       " [677.0, 445.0, 167],\n",
       " [955.0, 1061.0, 64],\n",
       " [561.0, 301.0, 196],\n",
       " [603.0, 381.0, 172],\n",
       " [525.0, 73.0, 219],\n",
       " [699.0, 793.0, 105],\n",
       " [561.0, 223.0, 196],\n",
       " [539.0, 133.0, 211],\n",
       " [797.0, 895.0, 74],\n",
       " [729.0, 893.0, 89],\n",
       " [769.0, 991.0, 69],\n",
       " [749.0, 731.0, 105],\n",
       " [479.0, 7.0, 255],\n",
       " [991.0, 939.0, 38],\n",
       " [827.0, 981.0, 58],\n",
       " [1067.0, 911.0, 62],\n",
       " [583.0, 429.0, 144],\n",
       " [525.0, 185.0, 214],\n",
       " [903.0, 931.0, 41],\n",
       " [989.0, 873.0, 59]]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_depth_in_circles(depth, detected_circles, max_th = 30):\n",
    "    depth_vector = []\n",
    "    for pt in detected_circles[0,:]:\n",
    "        x,y = pt[0],pt[1]\n",
    "        r = pt[2]\n",
    "\n",
    "        # print(x,y,r)\n",
    "        ix_min, ix_max = [np.max([np.floor(x-r),0]).astype(int), np.min([np.ceil(x+r),1080-1]).astype(int)]\n",
    "        iy_min, iy_max = (np.max([np.floor(y-r),0]).astype(int), np.min([np.ceil(y+r),1920-1]).astype(int))\n",
    "        \n",
    "        max = 0\n",
    "        for ix in range(ix_min, ix_max):\n",
    "            for iy in range(iy_min, iy_max):\n",
    "                # (ix,iy)\n",
    "                if( (ix-x)**2 + (iy-y)**2 <= r**2):\n",
    "                    # print(ix,iy,depth[iy,ix],depth[iy,ix]>max)\n",
    "                    if depth[iy,ix] > max:\n",
    "                        max = depth[iy,ix]\n",
    "                    # else:\n",
    "                    #     if max == 0:\n",
    "                    #         print('depth: ',depth[iy,ix])\n",
    "        # print('max =',max)\n",
    "        if max > max_th:\n",
    "            depth_vector.append([x,y,max])\n",
    "    return depth_vector\n",
    "\n",
    "\n",
    "check_depth_in_circles(depth,detected_circles,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def filter_detection(roi, r, circ_thresh=0.6, fill_thresh=0.6):\n",
    "    \"\"\"\n",
    "    Check if the ROI (grayscale) is near-circular and filled.\n",
    "    Uses Otsu's thresholding and contour analysis.\n",
    "    Returns True if both circularity and fill ratio exceed the thresholds.\n",
    "    \"\"\"\n",
    "    ret, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return False\n",
    "    cnt = max(contours, key=cv2.contourArea)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    if perimeter == 0:\n",
    "        return False\n",
    "    circularity = 4 * math.pi * (area / (perimeter * perimeter))\n",
    "    expected_area = math.pi * (r ** 2)\n",
    "    fill_ratio = area / expected_area if expected_area > 0 else 0\n",
    "    return (circularity >= circ_thresh) and (fill_ratio >= fill_thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using COCO anottations (manual labor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "dataDir='./DATASET/balls_distance_test'\n",
    "# dataType='val2017'\n",
    "annFile='{}/result.json'.format(dataDir)\n",
    "\n",
    "image_id = 1\n",
    "\n",
    "\n",
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)\n",
    "\n",
    "if image_id != coco.imgs[image_id]['id']:\n",
    "    print(\"ID diferente \")\n",
    "    image_id = coco.imgs[image_id]['id']\n",
    "\n",
    "imgFile='{}/images/{}'.format(dataDir,coco.imgs[image_id]['file_name'].split('/')[-1])\n",
    "raw_image = cv2.imread(imgFile)\n",
    "a,b,_ = raw_image.shape\n",
    "np.floor(a/14)*14\n",
    "np.floor(b/14)*14\n",
    "raw_image = raw_image[:int(np.floor(a/14)*14),:int(np.floor(b/14)*14),:]\n",
    "\n",
    "up_sampling = 4\n",
    "\n",
    "img_segmation = np.zeros([i*up_sampling for i in raw_image.shape[:2]],dtype=np.uint8)\n",
    "\n",
    "image_segmentatted = raw_image.copy()\n",
    "\n",
    "\n",
    "for key in coco.anns:\n",
    "    annotation = coco.anns[key]\n",
    "    if annotation['image_id'] == image_id:\n",
    "        seg_xy = np.array([ [annotation['segmentation'][0][i]*up_sampling, \n",
    "                             annotation['segmentation'][0][i+1]*up_sampling ] \n",
    "                                for i in range(0,len(annotation['segmentation'][0]),2)] \n",
    "                          ,dtype=np.int32)\n",
    "\n",
    "        cv2.fillPoly(img_segmation, [seg_xy], 255)\n",
    "        cv2.polylines(image_segmentatted, [seg_xy], 1, (255,255,255), 1)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"Check poli\", img_segmation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "imS = cv2.resize(img_segmation, (960, 540))                # Resize image\n",
    "cv2.imshow(\"output\", imS)                       # Show image\n",
    "cv2.waitKey(0)                                  # Display the image infinitely until any keypress\n",
    "\n",
    "\n",
    "cv2.imshow(\"Check poli\", image_segmentatted)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated 0.37308454513549805 Gb\n",
      "DEVICE: cuda\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/DepthAnything/Depth-Anything-V2?tab=readme-ov-file\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Memory allocated\", torch.cuda.memory_allocated()/1024/1024/1024,\"Gb\")\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n",
    "    \n",
    "encoder = 'vitb' # or 'vits', 'vitl', 'vitg'\n",
    "\n",
    "depth_anything = DepthAnythingV2(**model_configs[encoder])\n",
    "depth_anything.load_state_dict(torch.load(f'Depth-Anything-V2/depth_anything_v2_{encoder}.pth', map_location='cpu'))\n",
    "depth_anything = depth_anything.to(DEVICE).eval()\n",
    "\n",
    "\n",
    "depth = depth_anything.infer_image(raw_image,   np.floor(a/14)*14)\n",
    "\n",
    "depth = (depth - depth.min()) / (depth.max() - depth.min()) * 255.0\n",
    "depth = depth.astype(np.uint8)\n",
    "\n",
    "depth\n",
    "print(depth.min(), depth.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_depth_in_a_circle(depth, pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4312, 7672)\n",
      "677.75 444.75 4.900000095367432 and 2711.0 1779.0 19.6 and 146.93877265037278 146.93877265037278\n",
      "1140.75 158.25 5.699999809265137 and 4563.0 633.0 22.8 and 126.31579370049572 126.31579370049572\n",
      "749.25 731.25 4.050000190734863 and 2997.0 2925.0 16.2 and 177.77776940532874 177.77776940532874\n",
      "1107.75 569.25 4.25 and 4431.0 2277.0 17.0 and 169.41176470588232 169.41176470588232\n",
      "796.75 894.25 3.3499999046325684 and 3187.0 3577.0 13.4 and 214.92537925280044 214.92537925280044\n",
      "848.25 1028.75 2.4000000953674316 and 3393.0 4115.0 9.6 and 299.9999880790715 299.9999880790715\n",
      "826.75 980.75 2.5 and 3307.0 3923.0 10.0 and 288.0 288.0\n",
      "1085.75 786.25 4.050000190734863 and 4343.0 3145.0 16.2 and 177.77776940532874 177.77776940532874\n",
      "1055.25 978.75 2.3499999046325684 and 4221.0 3915.0 9.4 and 306.3829911570038 306.3829911570038\n",
      "1043.75 1018.25 2.200000047683716 and 4175.0 4073.0 8.8 and 327.2727201792821 327.2727201792821\n",
      "1068.25 910.75 2.9000000953674316 and 4273.0 3643.0 11.6 and 248.27585390433427 248.27585390433427\n",
      "868.75 1053.75 2.75 and 3475.0 4215.0 11.0 and 261.8181818181818 261.8181818181818\n",
      "1032.75 1032.75 1.75 and 4131.0 4131.0 7.0 and 411.4285714285714 411.4285714285714\n"
     ]
    }
   ],
   "source": [
    "# processed_img = blur_image(img_segmation,1,True,True,kernel2=2)\n",
    "processed_img = img_segmation\n",
    "\n",
    "print(\"shape:\", processed_img.shape)\n",
    "detected_circles = cv2.HoughCircles(processed_img,  \n",
    "                   cv2.HOUGH_GRADIENT, 2, 50, \n",
    "                   param1 = 50,     param2 = 10, # param1 = 50, param2= 10\n",
    "                   minRadius = 0,   maxRadius =10*up_sampling) \n",
    "\n",
    "\n",
    "vector_compare_radius_depth = []\n",
    "\n",
    "\n",
    "processed_img_color = cv2.cvtColor(processed_img, cv2.COLOR_GRAY2BGR )\n",
    "processed_img_color = cv2.resize(processed_img_color, raw_image.shape[:2])\n",
    "\n",
    "# print(len(detected_circles))\n",
    "# Draw circles that are detected. \n",
    "if detected_circles is not None: \n",
    "\n",
    "    for pt in detected_circles[0, :]: \n",
    "        a, b, r = pt[0]/up_sampling, pt[1]/up_sampling, pt[2]/up_sampling \n",
    "        print(a, b, r , 'and', pt[0], pt[1], pt[2], \"and\", calculate_distance(pt[2]/up_sampling), calculate_distance(r))\n",
    "        a, b, r = np.uint16((a,b,r))\n",
    "\n",
    "        depth_of_circle  = check_depth_in_a_circle(depth, pt)\n",
    "        # if depth_of_circle < 70:\n",
    "            # continue         \n",
    "\n",
    "        # Draw the circumference of the circle. \n",
    "\n",
    "        # Draw a small circle (of radius 1) to show the center. \n",
    "        # cv2.circle(img, (a, b), 1, (0, 0, 255), 3) \n",
    "        \n",
    "        # Write distances\n",
    "        text = str( round(calculate_distance(pt[2]/up_sampling) ) ) + '-' +str(round(depth_of_circle))\n",
    "        # text = str(round(depth_of_circle))\n",
    "        # text = str( round(pt[2],1) )\n",
    "        \n",
    "        \n",
    "        # # Extract ROI for extra filtering\n",
    "        # x_start = max(a - r, 0)\n",
    "        # y_start = max(b - r, 0)\n",
    "        # x_end = min(a + r, raw_image.shape[1])\n",
    "        # y_end = min(b + r, raw_image.shape[0])\n",
    "        # roi = raw_image[y_start:y_end, x_start:x_end]\n",
    "        \n",
    "        # # Apply extra filtering with relaxed thresholds\n",
    "        # # if filter_detection(roi, r, circ_thresh=0.6, fill_thresh=0.6):\n",
    "        cv2.circle(raw_image, (a, b), r, (255, 0, 0), 1) \n",
    "        cv2.circle(processed_img_color, (a, b), r, (0, 255, 0), 2) \n",
    "\n",
    "        # print(text)\n",
    "        cv2.putText(processed_img_color,text,(a,b),fontFace=1,fontScale=1,color=128,thickness=2,lineType=3)\n",
    "        cv2.putText(raw_image,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "        vector_compare_radius_depth.append([a, b, calculate_distance(pt[2]), depth_of_circle])\n",
    "\n",
    "cv2.imshow(\"Detected Circle\", processed_img_color) \n",
    "plt.show()\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# imS = cv2.resize(raw_image, (960, 540))                # Resize image\n",
    "# cv2.imshow(\"output\", imS)                       # Show image\n",
    "# cv2.waitKey(0)                                  # Display the image infinitely until any keypress\n",
    "\n",
    "\n",
    "cv2.imshow(\"Detected Circle\", raw_image) \n",
    "plt.show()\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([0.]), 60.698568378589506)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distantece_y = np.array([ i[2] for i in vector_compare_radius_depth])\n",
    "depth_x = np.array([ [i[3]] for i in vector_compare_radius_depth])\n",
    "\n",
    "plt.scatter(depth_x,distantece_y)\n",
    "\n",
    "distanceLR = LinearRegression().fit(depth_x,distantece_y)\n",
    "\n",
    "plt.plot(depth_x, depth_x * distanceLR.coef_[0] + distanceLR.intercept_, 'r:')\n",
    "plt.xlabel(\"Profundidade relativa\")\n",
    "plt.ylabel(\"Distancia [m]\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "distanceLR.coef_ , distanceLR.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
