{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Videos and estimate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\plima\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "c:\\Users\\plima\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Depth-Anything-V2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compress\n\u001b[1;32m---> 17\u001b[0m dpt \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDepth-Anything-V2.depth_anything_v2.dpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m DepthAnythingV2 \u001b[38;5;241m=\u001b[39m dpt\u001b[38;5;241m.\u001b[39mDepthAnythingV2\n\u001b[0;32m     20\u001b[0m util_transform \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDepth-Anything-V2.depth_anything_v2.util.transform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\plima\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Depth-Anything-V2'"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import importlib\n",
    "import math\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from itertools import compress\n",
    "\n",
    "dpt = importlib.import_module(\"Depth-Anything-V2.depth_anything_v2.dpt\")\n",
    "DepthAnythingV2 = dpt.DepthAnythingV2\n",
    "\n",
    "util_transform = importlib.import_module(\"Depth-Anything-V2.depth_anything_v2.util.transform\")\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros\n",
    "real_height = 400   # mm\n",
    "image_height = 1080 # pixels\n",
    "sensor_height = 5.4 # mm  \n",
    "focal_length = 32   # mm # Zoom\n",
    "image_width = 1920 # pixels\n",
    "# focal_length = 8   # mm # PTZ\n",
    "# Ta trocado PTZ e panoramica\n",
    "\n",
    "\n",
    "def calculate_distances(detected_circles, mode='reference'):\n",
    "\n",
    "    if mode == 'pixel_count':\n",
    "        distance_meters = []\n",
    "        # https://photo.stackexchange.com/questions/12434/how-do-i-calculate-the-distance-of-an-object-in-a-photo\n",
    "        dem = focal_length * real_height * image_height \n",
    "        for i in range(len(detected_circles)):\n",
    "            radius = detected_circles[i][2]\n",
    "            num = sensor_height * 2*radius \n",
    "            distance_meters.append(dem/num/1000)\n",
    "    else: # Reference Caternary method\n",
    "        # Reference distances in meters:\n",
    "        left_distances = [ 97.03452097, 132.67746731, 182.81089   , 238.42127226,\n",
    "                        296.38054131, 355.46744334, 415.11766024, 475.0301169 ,\n",
    "                        535.02450033, 594.9826379 , 654.82177347, 714.48134854,\n",
    "                        773.91599882, 833.09159591]\n",
    "        right_distances = [ 90.47079257, 112.05005222, 156.71269605, 210.19780552,\n",
    "                        267.20685889, 325.82715964, 385.24483613, 445.05429497,\n",
    "                        505.02550385, 565.01390556, 624.92128397, 684.67714093,\n",
    "                        744.22915224, 803.53794552]\n",
    "        middle_of_image = image_width/2\n",
    "        sorted_circles = sorted(detected_circles[0], key=lambda x: x[0])\n",
    "        mask = np.array([circle[0]< middle_of_image for circle in sorted_circles])\n",
    "        left_circles = list(compress(sorted_circles,mask))\n",
    "        right_circles = list(compress(sorted_circles,~mask))\n",
    "        distance_meters_left = np.zeros(len(left_circles))\n",
    "        distance_meters_right = np.zeros(len(right_circles))\n",
    "        \n",
    "        for i in range(len(left_circles)):\n",
    "            distance_meters_left[i] = left_distances[i]\n",
    "        for i in range(len(right_circles)):\n",
    "            distance_meters_right[len(right_circles)-i-1] = right_distances[i]\n",
    "        distance_meters = np.concatenate((distance_meters_left, distance_meters_right), axis=0)\n",
    "\n",
    "    return distance_meters\n",
    "\n",
    "def check_depth_in_a_circle(depth, pt, folga = 0):\n",
    "    x,y = pt[0],pt[1]\n",
    "    r = pt[2]\n",
    "\n",
    "    ix_min, ix_max = (np.max([np.floor(x-r),0]).astype(int), np.min([np.ceil(x+r),1918-1]).astype(int))\n",
    "    iy_min, iy_max = (np.max([np.floor(y-r),0]).astype(int), np.min([np.ceil(y+r),1078-1]).astype(int))\n",
    "\n",
    "    max = -999\n",
    "    for ix in range(ix_min-folga, ix_max+folga):\n",
    "        for iy in range(iy_min-folga, iy_max+folga):\n",
    "            if( (ix-x)**2 + (iy-y)**2 <= (r+folga)**2):\n",
    "\n",
    "                if depth[iy,ix] > max:\n",
    "                    max = depth[iy,ix]\n",
    "\n",
    "    return max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('./DATASET/results/10-10-2024\\\\10-10-2024_06-56-26_track_246_cam_0.avi_coordinates_tracking_242_cam_3.csv',\n",
       "  ['./DATASET/results/10-10-2024\\\\10-10-2024_06-56-26_track_246_cam_0.avi_coordinates_tracking_242_cam_3.csv']),\n",
       " ('./DATASET/results/10-10-2024\\\\10-10-2024_07-14-32_track_248_cam_0.avi_coordinates_tracking_247_cam_4.csv',\n",
       "  ['./DATASET/results/10-10-2024\\\\10-10-2024_07-14-32_track_248_cam_0.avi_coordinates_tracking_247_cam_4.csv']),\n",
       " ('./DATASET/results/10-10-2024\\\\10-10-2024_07-50-59_track_251_cam_0.avi_coordinates_tracking_249_cam_5.csv',\n",
       "  ['./DATASET/results/10-10-2024\\\\10-10-2024_07-50-59_track_251_cam_0.avi_coordinates_tracking_249_cam_5.csv'])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = glob.glob(\"./DATASET/results/10-10-2024/*.avi\")\n",
    "CSVs =  glob.glob(\"./DATASET/results/10-10-2024/*.csv\")\n",
    "up_sampling = 10\n",
    "\n",
    "[(CSVs[i], glob.glob(CSVs[i].split('track'+'*.avi')[0]) ) for i in range(len(CSVs))][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='./DATASET/balls_distance_test'\n",
    "# dataType='val2017'\n",
    "annFile='{}/result.json'.format(dataDir)\n",
    "\n",
    "image_id = 1\n",
    "\n",
    "def annotatio_to_circles(coco, image_id,SAVE_IMG = False):\n",
    "    # Take the anotted image and return the circles in it\n",
    "\n",
    "    up_sampling = 10 # Up sample to better detect circles\n",
    "    img_shape = [coco.imgs[0]['height'], coco.imgs[0]['width']]\n",
    "\n",
    "    img_segmation = np.zeros([i*up_sampling for i in img_shape],dtype=np.uint8)\n",
    "    seg_xy = []\n",
    "    for annotation in coco.imgToAnns[image_id]:\n",
    "        # annotation = coco.anns[key]\n",
    "        # if annotation['image_id'] == image_id:\n",
    "        seg_xy_up = np.array([ [annotation['segmentation'][0][i]*up_sampling, \n",
    "                                annotation['segmentation'][0][i+1]*up_sampling ] \n",
    "                                for i in range(0,len(annotation['segmentation'][0]),2)] \n",
    "                        ,dtype=np.int32)\n",
    "\n",
    "        cv2.fillPoly(img_segmation, [seg_xy_up], 128)\n",
    "\n",
    "        seg_xy.append( np.array([ [annotation['segmentation'][0][i], \n",
    "                            annotation['segmentation'][0][i+1] ] \n",
    "                                for i in range(0,len(annotation['segmentation'][0]),2)] \n",
    "                        ,dtype=np.int32)\n",
    "                    )\n",
    "            # cv2.polylines(image_segmentatted, [seg_xy], 1, (255,255,255), 1)\n",
    "\n",
    "    detected_circles = cv2.HoughCircles(img_segmation,  \n",
    "                   cv2.HOUGH_GRADIENT, 2, 20*up_sampling, \n",
    "                   param1 = 50,     param2 = 10, # param1 = 50, param2= 10\n",
    "                   minRadius = 1*up_sampling,   maxRadius =10*up_sampling) \n",
    "    if SAVE_IMG:\n",
    "        if detected_circles is not None: \n",
    "            detected_circles_sort = sorted(detected_circles[0,:], key=lambda x: x[0])\n",
    "            distances = calculate_distances(detected_circles/up_sampling, mode='reference')\n",
    "            for i,pt in enumerate(detected_circles_sort): \n",
    "                a, b, r = pt[0], pt[1], pt[2] \n",
    "                a, b, r = np.uint32((a,b,r))\n",
    "\n",
    "                # Write distances\n",
    "                text = str( round(distances[i]) ) + ' m;'\n",
    "                # Draw the circumference of the circle. \n",
    "                cv2.circle(img_segmation,(a, b),r, 255, 1) \n",
    "                cv2.putText(img_segmation,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "        if not 'segmentation' in os.listdir('./results/'):\n",
    "            os.mkdir('./results/segmentation')\n",
    "        cv2.imwrite(\"./results/segmentation/\"+coco.imgs[image_id]['file_name'].split('/')[-1].split('-',1)[1],img_segmation)\n",
    "\n",
    "\n",
    "    return detected_circles, seg_xy\n",
    "\n",
    "\n",
    "# detected_circles,seg_xy = annotatio_to_circles(coco, image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "processing image_id: 0  from  6\n",
      "processing image_id: 1  from  6\n",
      "processing image_id: 2  from  6\n",
      "processing image_id: 3  from  6\n",
      "processing image_id: 4  from  6\n",
      "processing image_id: 5  from  6\n",
      "processing image_id: 6  from  6\n"
     ]
    }
   ],
   "source": [
    "dataDir='./DATASET/balls_segmentation_out'\n",
    "annFile='{}/result.json'.format(dataDir)\n",
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)\n",
    "\n",
    "img_shape = [coco.imgs[0]['width'], coco.imgs[0]['height']]\n",
    "up_sampling = 10 # Up sample to better detect circles\n",
    "\n",
    "balls_distance = {}\n",
    "for image_id in coco.getImgIds():\n",
    "    image_name = coco.imgs[image_id]['file_name'].split('/')[-1].split('-',1)[1]\n",
    "    balls_distance[image_name] = {}\n",
    "    \n",
    "    print('processing image_id:',image_id,' from ', max(coco.getImgIds()) )\n",
    "    detected_circles,seg_xy = annotatio_to_circles(coco, image_id,True)\n",
    "\n",
    "    balls_distance[image_name]['detected_circles'] = detected_circles \n",
    "    balls_distance[image_name]['segmentation_coordinates'] = seg_xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_depth(raw_image):\n",
    "    # Create depth image\n",
    "    # https://github.com/DepthAnything/Depth-Anything-V2?tab=readme-ov-file\n",
    "    torch.cuda.empty_cache()    \n",
    "    if(torch.cuda.memory_allocated()/1024/1024/1024 > 2):\n",
    "        print(\"Memory allocated\", torch.cuda.memory_allocated()/1024/1024/1024,\"Gb\")\n",
    "\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"warning device:\", DEVICE)\n",
    "    \n",
    "    raw_image_h,raw_image_w,_ = raw_image.shape\n",
    "    model_configs = {\n",
    "        'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "        'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "        'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "        'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "    }\n",
    "        \n",
    "    encoder = 'vitb' # or 'vits', 'vitl', 'vitg'\n",
    "\n",
    "    depth_anything = DepthAnythingV2(**model_configs[encoder])\n",
    "    depth_anything.load_state_dict(torch.load(f'Depth-Anything-V2/depth_anything_v2_{encoder}.pth', map_location='cpu'))\n",
    "    depth_anything = depth_anything.to(DEVICE).eval()\n",
    "\n",
    "    # Use model\n",
    "    depth = depth_anything.infer_image(raw_image, np.floor(raw_image_h/14)*14)\n",
    "\n",
    "    normalize = False\n",
    "    # Transform in \n",
    "    if normalize:\n",
    "        depth = (depth - depth.min()) / (depth.max() - depth.min()) * 255.0\n",
    "        depth = depth.astype(np.uint8)\n",
    "\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_depth_to_meters(detected_circles, depth, SAVE_FIGS = False, raw_image = np.array([0]),folga=0):\n",
    "    \n",
    "    # Check depth in places that we now the\n",
    "    vector_compare_radius_depth = []\n",
    "    \n",
    "    image_with_detection = raw_image.copy()\n",
    "\n",
    "    if detected_circles is not None: \n",
    "        detected_circles_sort = sorted(detected_circles[0,:], key=lambda x: x[0])\n",
    "        distances = calculate_distances(detected_circles/up_sampling, mode='reference')\n",
    "\n",
    "        for i, pt in enumerate(detected_circles_sort): \n",
    "            a, b, r = pt[0]/up_sampling, pt[1]/up_sampling, pt[2]/up_sampling \n",
    "            a, b, r = np.uint32((a,b,r))\n",
    "\n",
    "            depth_of_circle  = check_depth_in_a_circle(depth, (pt[0]/up_sampling, pt[1]/up_sampling, pt[2]/up_sampling),folga=20)\n",
    "\n",
    "            # Write distances\n",
    "            text = str( round(distances[i]) ) + ' m; ' \\\n",
    "                    + str(round(depth_of_circle,3)) + \"depth\"\n",
    "            \n",
    "            if SAVE_FIGS:\n",
    "                # Draw the circumference of the circle. \n",
    "                cv2.circle(image_with_detection,(a, b),r+folga,(255, 0, 0), 1) \n",
    "                cv2.putText(image_with_detection,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "            \n",
    "            # cv2.circle(processed_img,(a, b),r,(255, 0, 0), 1) \n",
    "            # cv2.putText(processed_img,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "\n",
    "            vector_compare_radius_depth.append([a, b, distances[i], depth_of_circle])\n",
    "\n",
    "\n",
    "    ## Calculate the relationship between depth and distance\n",
    "    distantece_y = np.array([ i[2] for i in vector_compare_radius_depth])\n",
    "    depth_x = np.array([ [i[3]] for i in vector_compare_radius_depth])\n",
    "    inv_depth_x = 1/depth_x\n",
    "    \n",
    "\n",
    "\n",
    "    distanceLR = LinearRegression().fit(inv_depth_x,distantece_y)\n",
    "    new_vector_compare_radius_depth = []\n",
    "    # new_depth_x = []\n",
    "    # new_distantece_y = []\n",
    "    new_vector_check = vector_compare_radius_depth\n",
    "    if False: # Use or not use outliers\n",
    "        while len(new_vector_check) != len(new_vector_compare_radius_depth) or \\\n",
    "            new_vector_check != new_vector_compare_radius_depth:\n",
    "\n",
    "            new_vector_compare_radius_depth = []\n",
    "            for eta in vector_compare_radius_depth:\n",
    "                loss = (eta[3] * distanceLR.coef_[0] + distanceLR.intercept_ - eta[2])**2\n",
    "                if loss < 1000:\n",
    "                    new_vector_compare_radius_depth.append(eta)\n",
    "\n",
    "            new_distantece_y = np.array([ i[2] for i in new_vector_compare_radius_depth])\n",
    "            new_depth_x = np.array([ [i[3]] for i in new_vector_compare_radius_depth])\n",
    "\n",
    "            distanceLR = LinearRegression().fit(new_depth_x,new_distantece_y)\n",
    "            new_vector_check = new_vector_compare_radius_depth\n",
    "\n",
    "    return [distanceLR.coef_ , distanceLR.intercept_], image_with_detection, (depth_x, distantece_y, new_vector_compare_radius_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_distance(depth, coefs, track):\n",
    "    \n",
    "    if type(track['coordinates_x1']) == type('string'):\n",
    "        ix_min = int(float(track['coordinates_x1'].replace(',','.')))\n",
    "        ix_max = int(np.ceil(float(track['coordinates_x2'].replace(',','.'))))\n",
    "        iy_min = int(float(track['coordinates_y1'].replace(',','.')))\n",
    "        iy_max = int(np.ceil(float(track['coordinates_y2'].replace(',','.'))))\n",
    "    else:\n",
    "        ix_min = int(track['coordinates_x1'])\n",
    "        ix_max = int(np.ceil(track['coordinates_x2']))\n",
    "        iy_min = int(track['coordinates_y1'])\n",
    "        iy_max = int(np.ceil(track['coordinates_y2']))\n",
    "\n",
    "    max_depth = 0\n",
    "    for ix in range(ix_min, ix_max):\n",
    "        for iy in range(iy_min, iy_max):\n",
    "            if depth[iy,ix] > max_depth:\n",
    "                max_depth = depth[iy,ix]\n",
    "\n",
    "    if max_depth > 0:    \n",
    "        distance = (1/max_depth)*coefs[0] + coefs[1]\n",
    "        return distance[0], max_depth\n",
    "    return -1, max_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seg_img(filename,seg_file_names):\n",
    "    for i, seg_name in enumerate(seg_file_names[:-1]):\n",
    "        if filename > seg_name and filename < seg_file_names[i+1]:\n",
    "            return seg_name\n",
    "    return seg_file_names[-1]\n",
    "\n",
    "seg_file_names = [coco.imgs[id]['file_name'].split('/')[-1].split('-',1)[1] for id in coco.getImgIds()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circles(frame, detected_circles, folga = 0):\n",
    "    # print(len(detected_circles))\n",
    "    # Draw circles that are detected. \n",
    "    if detected_circles is not None: \n",
    "        detected_circles_sort = sorted(detected_circles[0,:], key=lambda x: x[0])\n",
    "        distances = calculate_distances(detected_circles/up_sampling, mode='reference')\n",
    "        for i,pt in enumerate(detected_circles_sort): \n",
    "            a, b, r = pt[0]/up_sampling, pt[1]/up_sampling, pt[2]/up_sampling \n",
    "            a, b, r = np.uint32((a,b,r))\n",
    "\n",
    "            depth_of_circle  = check_depth_in_a_circle(depth, (pt[0]/up_sampling, pt[1]/up_sampling, pt[2]/up_sampling))\n",
    "\n",
    "            # Write distances\n",
    "            text = str( round(distances[i] ) ) + '; ' +str(round(depth_of_circle))\n",
    "            \n",
    "            # Draw the circumference of the circle. \n",
    "            cv2.circle(frame,(a, b),r,(255, 0, 0), 1)\n",
    "            if folga:\n",
    "                cv2.circle(frame,(a, b),r+folga,(0, 255, 0),2) \n",
    "            cv2.putText(frame,text,(a,b),fontFace=1,fontScale=1,color=255)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overlap(detected_circles, track, folga=0):\n",
    "    # Return 1 if overlap\n",
    "\n",
    "    if type(track['coordinates_x1']) == type('string'):\n",
    "        ix_min = int(float(track['coordinates_x1'].replace(',','.')))\n",
    "        ix_max = int(np.ceil(float(track['coordinates_x2'].replace(',','.'))))\n",
    "        iy_min = int(float(track['coordinates_y1'].replace(',','.')))\n",
    "        iy_max = int(np.ceil(float(track['coordinates_y2'].replace(',','.'))))\n",
    "    else:\n",
    "        ix_min = int(track['coordinates_x1'])\n",
    "        ix_max = int(np.ceil(track['coordinates_x2']))\n",
    "        iy_min = int(track['coordinates_y1'])\n",
    "        iy_max = int(np.ceil(track['coordinates_y2']))\n",
    "\n",
    "    corners = [\n",
    "        [ix_min, iy_min],\n",
    "        [ix_min, iy_max],\n",
    "        [ix_max, iy_min],\n",
    "        [ix_max, iy_max]\n",
    "    ]\n",
    "\n",
    "\n",
    "    for pt in detected_circles[0, :]: \n",
    "        a, b, r = pt[0]/up_sampling, pt[1]/up_sampling, pt[2]/up_sampling \n",
    "        for c in corners:\n",
    "            if (a-c[0])**2 + (b-c[1])**2 <= (r+folga)**2:\n",
    "                return 1\n",
    "    \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outputs(filename, frame, depth, image_with_detection, bird_d, track, coefs, detected_circles, regression_points, seg_xy, folga, path = \"./results/\"):\n",
    "\n",
    "\n",
    "    image_segmentatted = frame.copy()\n",
    "    # image_with_detection = frame.copy()\n",
    "    image_with_selected_detections = depth.copy()\n",
    "    image_with_selected_detections = image_with_selected_detections/image_with_selected_detections.max()*255\n",
    "    depth_w_bird = image_with_selected_detections.copy()\n",
    "\n",
    "    if type(track['coordinates_x1']) == type('string'):\n",
    "        ix_min = int(float(track['coordinates_x1'].replace(',','.')))\n",
    "        ix_max = int(np.ceil(float(track['coordinates_x2'].replace(',','.'))))\n",
    "        iy_min = int(float(track['coordinates_y1'].replace(',','.')))\n",
    "        iy_max = int(np.ceil(float(track['coordinates_y2'].replace(',','.'))))\n",
    "    else:\n",
    "        ix_min = int(track['coordinates_x1'])\n",
    "        ix_max = int(np.ceil(track['coordinates_x2']))\n",
    "        iy_min = int(track['coordinates_y1'])\n",
    "        iy_max = int(np.ceil(track['coordinates_y2']))\n",
    "\n",
    "    image_with_detection = draw_circles(image_with_detection, detected_circles, folga)\n",
    "    image_with_selected_detections = draw_circles(image_with_selected_detections, detected_circles, folga)\n",
    "    cv2.rectangle(depth_w_bird,(ix_min,iy_min),(ix_max,iy_max),(255,255,255),2 )\n",
    "    cv2.putText(depth_w_bird,str(round(bird_d,1))+\" m\",(ix_max,iy_max),fontFace=1,fontScale=1,color=255)\n",
    "\n",
    "    cv2.rectangle(depth_w_bird,(ix_min,iy_min),(ix_max,iy_max),(255,255,255),2 )\n",
    "    cv2.putText(depth_w_bird,str(round(bird_d,1))+\" m\",(ix_max,iy_max),fontFace=1,fontScale=1,color=255)\n",
    "    (depth_x, distantece_y, new_vector_compare_radius_depth) = regression_points\n",
    "    new_distantece_y = np.array([ i[2] for i in new_vector_compare_radius_depth])\n",
    "    new_depth_x = np.array([ [i[3]] for i in new_vector_compare_radius_depth])\n",
    "\n",
    "    for x,y,_,_ in new_vector_compare_radius_depth:\n",
    "        cv2.circle(image_with_selected_detections, (x,y), 1,(0, 0, 255), 2) \n",
    "\n",
    "\n",
    "    plt.ioff()\n",
    "    # print([seg_xy])\n",
    "    cv2.fillPoly(image_segmentatted, seg_xy, 255)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.imshow(frame)\n",
    "    plt.title(\"frame\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.imshow(image_segmentatted)\n",
    "    plt.title(\"frame with ball Segmentation\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.imshow(depth_w_bird)\n",
    "    plt.title(\"Depth with bird (d = \" + str(round(bird_d,2)) + \"m )\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.imshow(image_with_detection)\n",
    "    plt.title(\"Circulos detectado\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.imshow(image_with_selected_detections)\n",
    "    plt.title(\"Circulos utilizados (azul)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.scatter(1/depth_x,distantece_y,c='b',alpha=.5)\n",
    "    # plt.scatter(new_depth_x,new_distantece_y,c='k')\n",
    "    plt.plot(1/depth_x, 1/depth_x * coefs[0][0] + coefs[1], 'r*')\n",
    "    plt.xlabel(\"Inverso da Profundidade relativa (a=\"+str(np.round(coefs[0][0],2))+\", b=\"+str(np.round(coefs[1],1))+\")\" )\n",
    "    plt.ylabel(\"Distancia [m]\")\n",
    "    plt.title(\"Calculo da distancia\")\n",
    "    # plt.xlim((0, np.max(depth_x)+1))\n",
    "    # plt.ylim(( 0 , np.max(distantece_y)+20))\n",
    "    # plt.legend([\"Todos valores\",\"Valores selecionados\",\"Regressão\"])\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(path + filename +'.png',dpi=600)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_cables(depth, th=.5):\n",
    "    # Mask the cables\n",
    "    mask = np.zeros(depth.shape, dtype=np.uint8)\n",
    "    mask[depth > th] = 255\n",
    "    return mask\n",
    "\n",
    "def check_bird_in_mask(track, mask_cable, folga=10):\n",
    "    # Check if the bird is in the mask\n",
    "    ix_min = int(track['coordinates_x1'])\n",
    "    ix_min_folga = int(track['coordinates_x1']) - folga\n",
    "    ix_max = int(np.ceil(track['coordinates_x2']))\n",
    "    ix_max_folga = int(np.ceil(track['coordinates_x2'])) + folga\n",
    "    iy_min = int(track['coordinates_y1'])\n",
    "    iy_min_folga = int(track['coordinates_y1']) - folga\n",
    "    iy_max = int(np.ceil(track['coordinates_y2']))\n",
    "    iy_max_folga = int(np.ceil(track['coordinates_y2'])) + folga\n",
    "    # Check if the coordinates are within the image bounds\n",
    "    if ix_min_folga < 0:\n",
    "        ix_min_folga = 0\n",
    "    if ix_max_folga > mask_cable.shape[1]:\n",
    "        ix_max_folga = mask_cable.shape[1] \n",
    "    if iy_min_folga < 0:      \n",
    "        iy_min_folga = 0  \n",
    "    if iy_max_folga > mask_cable.shape[0]:    \n",
    "        iy_max_folga = mask_cable.shape[0]    \n",
    "    \n",
    "    for ix in range(ix_min_folga, ix_max_folga):\n",
    "        for iy in range(iy_min_folga, iy_max_folga):\n",
    "            if ix >= ix_min and ix <= ix_max and iy >= iy_min and iy <= iy_max:\n",
    "                continue\n",
    "            if mask_cable[iy,ix] == 255:\n",
    "                # print(iy,ix, \"mask:\", mask_cable[iy,ix]) \n",
    "                # print(\"depth:\", depth[iy,ix], \"_depth:\", depth[ix,iy]) \n",
    "                # print(\"Bird in mask\", track['coordinates_x1'],track['coordinates_x2'],track['coordinates_y1'],track['coordinates_y2'])\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "# check_bird_in_mask(track, mask_cable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frames: 1767 tempo estimado (8 segundos por frame): 3.93 horas\n"
     ]
    }
   ],
   "source": [
    "tamanho_total = 0\n",
    "for i,CSV in enumerate(CSVs):\n",
    "    dfTracking = pd.read_csv(CSV)\n",
    "    tamanho_total+= len(dfTracking)\n",
    "\n",
    "print(\"Total de frames:\", tamanho_total,\"tempo estimado (8 segundos por frame):\", round(tamanho_total*8/60/60,2),\"horas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video num: 3 of 24 . video file = 10-10-2024_07-50-59_track_251_cam_0.avi_track_249_cam_5.avi  CSV file: 10-10-2024_07-50-59_track_251_cam_0.avi_coordinates_tracking_249_cam_5.csv\n",
      "frame 9 of 25------- img filename:  10-10-2024_07-50-59_track_251_cam_0.avi_track_249_cam_5.avi_frame_9.0\r"
     ]
    }
   ],
   "source": [
    "# Evaluate vídeos\n",
    "folga = 20\n",
    "\n",
    "ret = True\n",
    "frame_number = 1\n",
    "for i,CSV in enumerate(CSVs):\n",
    "    if i!=1:\n",
    "        continue\n",
    "    dfTracking = pd.read_csv(CSV)\n",
    "\n",
    "    video = glob.glob(CSV.split('track')[0]+'*.avi')\n",
    "    if len(video) > 1:\n",
    "        print(f\"Warning on CSV {CSV} and video: {video}\")\n",
    "    video = video[0]\n",
    "    \n",
    "    print(\"video num:\",i+1,\"of\",len(videos),\". video file =\",video.split('\\\\')[-1],\" CSV file:\",CSV.split('\\\\')[-1])\n",
    "    \n",
    "    dfDistance = pd.DataFrame(columns=dfTracking.columns) \n",
    "    dfDistance['video_file'] = []       # video file name\n",
    "    dfDistance['bird_distance'] = []    # bird distance in meters\n",
    "    dfDistance['bird_Depth'] = []       # bird relative depth \n",
    "    dfDistance['coefs'] = []            # coefficients for linear regression\n",
    "    dfDistance['ref_depth_values'] = []     # ordered depth values for reference\n",
    "    dfDistance['ref_distance_values'] = []  # ordered distance values for reference\n",
    "    dfDistance['ref_choosen_points'] = []   # choosen points of reference\n",
    "    dfDistance['ref_circles'] = []           # Name of the reference image for circle sizes\n",
    "    dfDistance['ignore'] = []           # Name of the reference image for circle sizes\n",
    "    circles_ref = find_seg_img(video,seg_file_names)\n",
    "    detected_circles = balls_distance[circles_ref]['detected_circles']\n",
    "    \n",
    "    cap = cv2.VideoCapture(video)\n",
    "\n",
    "    for j, track in dfTracking.iterrows():\n",
    "\n",
    "        # start = time.time()\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, track['current_frame']-1)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"frame \",str(track['current_frame']), \" não lido\")\n",
    "            continue\n",
    "        depth = create_depth(frame)\n",
    "\n",
    "        mask_cable = mask_cables(depth)\n",
    "\n",
    "        coefs, image_with_detection, regression_points = create_depth_to_meters(detected_circles, depth,SAVE_FIGS = True, raw_image = frame)\n",
    "        bird_d, bird_depth = bird_distance(depth, coefs, track)\n",
    "\n",
    "        (depth_x, distantece_y, new_vector_compare_radius_depth) = regression_points\n",
    "\n",
    "        toDataframe = list(track.values)\n",
    "        toDataframe.append(video.split('\\\\')[-1])\n",
    "        toDataframe.append(bird_d)\n",
    "        toDataframe.append(bird_depth)            #bird_Depth\n",
    "        toDataframe.append(coefs)  #coefs\n",
    "        toDataframe.append(depth_x)            #ref_depth_values\n",
    "        toDataframe.append(distantece_y)            #ref_distance_values\n",
    "        toDataframe.append(new_vector_compare_radius_depth)            #ref_choosen_points\n",
    "        toDataframe.append(circles_ref)            # ref_circles\n",
    "        toDataframe.append(check_overlap(detected_circles,track,folga) # balls\n",
    "                           or check_bird_in_mask(track, mask_cable) # Mask\n",
    "                           ) # ignore\n",
    "        dfDistance.loc[len(dfDistance)] = toDataframe\n",
    "\n",
    "        filename = video.split('\\\\')[-1]+\"_frame_\"+str(track['current_frame'])\n",
    "        if True:\n",
    "            create_outputs(filename, frame, depth, image_with_detection, bird_d, track, coefs, detected_circles, \n",
    "                           regression_points, balls_distance[circles_ref]['segmentation_coordinates'], folga, \n",
    "                           path = \"./results/\")\n",
    "        # break\n",
    "        print(f'frame {j+1} of {len(dfTracking)}------- img filename: ',filename,end='\\r')\n",
    "\n",
    "    cap.release()\n",
    "    # Save a CSV per video\n",
    "    dfDistance.to_csv(\"./results/\"+ video.split('\\\\')[-1] + \".csv\")\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rascunhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask():\n",
    "    folga = 5\n",
    "    ix_min = int(track['coordinates_x1'])\n",
    "    ix_min_folga = int(track['coordinates_x1']) - folga\n",
    "    ix_max = int(np.ceil(track['coordinates_x2']))\n",
    "    ix_max_folga = int(np.ceil(track['coordinates_x2'])) + folga\n",
    "    iy_min = int(track['coordinates_y1'])\n",
    "    iy_min_folga = int(track['coordinates_y1']) - folga\n",
    "    iy_max = int(np.ceil(track['coordinates_y2']))\n",
    "    iy_max_folga = int(np.ceil(track['coordinates_y2'])) + folga\n",
    "\n",
    "    cv2.rectangle(depth,(ix_min,iy_min),(ix_max,iy_max),(255,255,255),2 )\n",
    "    cv2.rectangle(depth,(ix_min_folga,iy_min_folga),(ix_max_folga,iy_max_folga),(255,255,255),2 )\n",
    "\n",
    "    cv2.imshow('depth',mask_cables(depth,th=.5))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
